{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "魔兽世界坐骑去哪买\n",
      "奥比岛在哪有皇室舞会的邀请函？\n",
      "在淘宝去哪里充值好\n",
      "在淘宝里怎么买火车票，哪里有\n",
      "鱼不可以和什么蔬菜一起吃\n",
      "鱼不能和什么药物一起吃\n",
      "读音是什么？怎么组词\n",
      "熙的读音和组词是什么？\n",
      "七夕到了，单身该怎么过啊？\n",
      "七夕单身的人怎么过？\n",
      "什么品牌的智能手机好用\n",
      "现在什么牌子的智能手机好用，又便宜呀\n",
      "一个人怎么过七夕？\n",
      "七夕一个人怎么过\n"
     ]
    }
   ],
   "source": [
    "path = './day4.text'\n",
    "\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_embedding(s):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        s (str): the sentence to embed\n",
    "\n",
    "    Returns:\n",
    "        list: the embedding list\n",
    "    \"\"\"\n",
    "    url = 'https://openai.api2d.net/v1/embeddings'\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        # <-- 把 fkxxxxx 替换成你自己的 Forward Key，注意前面的 Bearer 要保留，并且和 Key 中间有一个空格。\n",
    "        'Authorization': 'Bearer fk212271-eTpF7inqXN1UJ6FPQgRDCRkpv2K9zsmn'\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        'model': 'text-embedding-ada-002',\n",
    "        'input': s\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    print('Status Code', response.status_code)\n",
    "    response_json = response.json()\n",
    "    # print('JSON Response ', response_json)\n",
    "    embedding = response_json['data'][0]['embedding']\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "def get_bert_embedding(s):\n",
    "    from transformers import BertTokenizer, BertModel, logging\n",
    "    logging.set_verbosity_error()\n",
    "\n",
    "    # Load pre-trained BERT model and tokenizer\n",
    "    model_name = 'bert-base-chinese'\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "    # Example sentence\n",
    "    # sentence = \"This is an example sentence.\"\n",
    "\n",
    "    # Tokenize input\n",
    "    tokens = tokenizer.encode(s, add_special_tokens=True)\n",
    "\n",
    "    # Convert tokens to tensor\n",
    "    input_ids = torch.tensor([tokens])\n",
    "\n",
    "    # Get BERT model output\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "    # Extract sentence embedding\n",
    "    sentence_embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "    # Print the sentence embedding\n",
    "    print(type(sentence_embedding))\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code 200\n",
      "<class 'torch.Tensor'>\n",
      "Status Code 200\n",
      "<class 'torch.Tensor'>\n",
      "Status Code 200\n",
      "<class 'torch.Tensor'>\n",
      "Status Code 200\n",
      "<class 'torch.Tensor'>\n",
      "Status Code 200\n",
      "<class 'torch.Tensor'>\n",
      "Status Code 200\n",
      "<class 'torch.Tensor'>\n",
      "Status Code 200\n",
      "<class 'torch.Tensor'>\n",
      "Status Code 200\n",
      "<class 'torch.Tensor'>\n",
      "Status Code 200\n",
      "<class 'torch.Tensor'>\n",
      "Status Code 200\n",
      "<class 'torch.Tensor'>\n",
      "Status Code 200\n",
      "<class 'torch.Tensor'>\n",
      "Status Code 200\n",
      "<class 'torch.Tensor'>\n",
      "Status Code 200\n",
      "<class 'torch.Tensor'>\n",
      "Status Code 200\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "gpt_embeddings = dict()\n",
    "bert_embeddings = dict()\n",
    "path = './day4.text'\n",
    "\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        gpt_embeddings[line] = get_gpt_embedding(line)\n",
    "        bert_embeddings[line] = get_bert_embedding(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([1, 1536])\n",
      "torch.Size([1, 1536])\n",
      "torch.Size([1, 1536])\n",
      "torch.Size([1, 1536])\n",
      "torch.Size([1, 1536])\n",
      "torch.Size([1, 1536])\n",
      "torch.Size([1, 1536])\n",
      "torch.Size([1, 1536])\n",
      "torch.Size([1, 1536])\n",
      "torch.Size([1, 1536])\n",
      "torch.Size([1, 1536])\n",
      "torch.Size([1, 1536])\n",
      "torch.Size([1, 1536])\n",
      "torch.Size([1, 1536])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n",
      "魔兽世界坐骑去哪买 torch.Size([1, 1536])\n",
      "奥比岛在哪有皇室舞会的邀请函？ torch.Size([1, 1536])\n",
      "在淘宝去哪里充值好 torch.Size([1, 1536])\n",
      "在淘宝里怎么买火车票，哪里有 torch.Size([1, 1536])\n",
      "鱼不可以和什么蔬菜一起吃 torch.Size([1, 1536])\n",
      "鱼不能和什么药物一起吃 torch.Size([1, 1536])\n",
      "读音是什么？怎么组词 torch.Size([1, 1536])\n",
      "熙的读音和组词是什么？ torch.Size([1, 1536])\n",
      "七夕到了，单身该怎么过啊？ torch.Size([1, 1536])\n",
      "七夕单身的人怎么过？ torch.Size([1, 1536])\n",
      "什么品牌的智能手机好用 torch.Size([1, 1536])\n",
      "现在什么牌子的智能手机好用，又便宜呀 torch.Size([1, 1536])\n",
      "一个人怎么过七夕？ torch.Size([1, 1536])\n",
      "七夕一个人怎么过 torch.Size([1, 1536])\n",
      "魔兽世界坐骑去哪买 torch.Size([1, 768])\n",
      "奥比岛在哪有皇室舞会的邀请函？ torch.Size([1, 768])\n",
      "在淘宝去哪里充值好 torch.Size([1, 768])\n",
      "在淘宝里怎么买火车票，哪里有 torch.Size([1, 768])\n",
      "鱼不可以和什么蔬菜一起吃 torch.Size([1, 768])\n",
      "鱼不能和什么药物一起吃 torch.Size([1, 768])\n",
      "读音是什么？怎么组词 torch.Size([1, 768])\n",
      "熙的读音和组词是什么？ torch.Size([1, 768])\n",
      "七夕到了，单身该怎么过啊？ torch.Size([1, 768])\n",
      "七夕单身的人怎么过？ torch.Size([1, 768])\n",
      "什么品牌的智能手机好用 torch.Size([1, 768])\n",
      "现在什么牌子的智能手机好用，又便宜呀 torch.Size([1, 768])\n",
      "一个人怎么过七夕？ torch.Size([1, 768])\n",
      "七夕一个人怎么过 torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "\n",
    "for line, embedding in gpt_embeddings.items():\n",
    "    gpt_embeddings[line] = torch.tensor(embedding).unsqueeze(0)\n",
    "    # torch.Size([1, 1536])\n",
    "    print(gpt_embeddings[line].shape) \n",
    "\n",
    "for line, embedding in bert_embeddings.items():\n",
    "    # torch.Size([1, 768])\n",
    "    print(embedding.shape)\n",
    "\n",
    "\n",
    "for line in gpt_embeddings:\n",
    "    print(line, gpt_embeddings[line].shape)\n",
    "\n",
    "for line in bert_embeddings:\n",
    "    print(line, bert_embeddings[line].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "[[0.74071497]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cos(a, b):\n",
    "    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n",
    "    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n",
    "    # print(a_norm, a.shape)\n",
    "    # print(b_norm, b.shape)\n",
    "    res = torch.mm(a_norm, b_norm.transpose(0, 1)).detach().numpy()\n",
    "    print(res.shape)\n",
    "    return res\n",
    "\n",
    "a = torch.rand((1, 768))\n",
    "b = torch.rand_like(a)\n",
    "print(cos(a, b))\n",
    "\n",
    "def eu_dist(a, b):\n",
    "    return torch.cdist(a, b, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "魔兽世界坐骑去哪买\n",
      "奥比岛在哪有皇室舞会的邀请函？\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "[[0.7675891]] [[0.7143903]] 0\n",
      "----\n",
      "在淘宝去哪里充值好\n",
      "在淘宝里怎么买火车票，哪里有\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "[[0.86941403]] [[0.8413911]] 0\n",
      "----\n",
      "鱼不可以和什么蔬菜一起吃\n",
      "鱼不能和什么药物一起吃\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "[[0.9369331]] [[0.9460966]] 0\n",
      "----\n",
      "读音是什么？怎么组词\n",
      "熙的读音和组词是什么？\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "[[0.90035325]] [[0.8942231]] 1\n",
      "----\n",
      "七夕到了，单身该怎么过啊？\n",
      "七夕单身的人怎么过？\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "[[0.9324024]] [[0.97096115]] 1\n",
      "----\n",
      "什么品牌的智能手机好用\n",
      "现在什么牌子的智能手机好用，又便宜呀\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "[[0.9333664]] [[0.9471439]] 1\n",
      "----\n",
      "一个人怎么过七夕？\n",
      "七夕一个人怎么过\n",
      "(1, 1)\n",
      "(1, 1)\n",
      "[[0.9503025]] [[0.94525594]] 1\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "path = './day4.text'\n",
    "\n",
    "label = deque([0] * 3 + [1] * 4)\n",
    "bert_grade = gpt_grade = 0\n",
    "\n",
    "\"\"\"\n",
    "Use cosine similarity as the evaluation metric. Larger values represent closer relationships. \n",
    "Cosine similarity should be smaller when the label is 0, i.e., when the two sentences are not related. \n",
    "Conversely, it should be larger. \n",
    "So the formula is: sum(cos_sim between pairs with label 1) - sum(cos_sim between pairs with label 0).\n",
    "If use eu_dist as the evaluation metric, all we need is to just take the opposite of the result of the above formula\n",
    "Thus the higher grade represents the better performance.\n",
    "\"\"\"\n",
    "\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    while True:\n",
    "        line1 = file.readline().strip()  # Read the first line\n",
    "        line2 = file.readline().strip()  # Read the second line\n",
    "\n",
    "        if not line2:  # Check if the second line is empty (end of file)\n",
    "            break\n",
    "\n",
    "        # Process the two lines\n",
    "        print(line1)\n",
    "        print(line2)\n",
    "        l = label.popleft()\n",
    "\n",
    "        bert_cos_sim = cos(bert_embeddings[line1], bert_embeddings[line2])\n",
    "        gpt_cos_sim = cos(gpt_embeddings[line1], gpt_embeddings[line2])\n",
    "        bert_grade += bert_cos_sim if l else -bert_cos_sim\n",
    "        gpt_grade += gpt_cos_sim if l else -gpt_cos_sim\n",
    "        print(bert_cos_sim, gpt_cos_sim, l)\n",
    "\n",
    "        # bert_eu_dis = eu_dist(bert_embeddings[line1], bert_embeddings[line2])\n",
    "        # gpt_eu_dis = eu_dist(gpt_embeddings[line1], gpt_embeddings[line2])\n",
    "        # bert_grade -= bert_eu_dis if l else -bert_eu_dis\n",
    "        # gpt_grade -= gpt_eu_dis if l else -gpt_eu_dis\n",
    "        # print(bert_eu_dis, gpt_eu_dis, l)\n",
    "\n",
    "        print('----')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_grade: [[1.1424882]]\n",
      "gpt_grade: [[1.2557061]]\n",
      "Which one is better, bert or gpt?\n",
      "gpt-text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "print(f'bert_grade: {bert_grade}')\n",
    "print(f'gpt_grade: {gpt_grade}')\n",
    "print('Which one is better, bert or gpt?')\n",
    "print('bert-base-chinese' if bert_grade > gpt_grade else 'gpt-text-embedding-ada-002')\n",
    "# cos: gpt-text-embedding-ada-002 win\n",
    "# eu_dist: bert-base-chinese win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yyk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
